{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e320a1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the path to the directory containing your module\n",
    "sys.path.append(os.path.abspath('/projectnb/textconv/dgwave/AudioSCC/data'))\n",
    "sys.path.append(os.path.abspath('/projectnb/textconv/dgwave/AudioSCC/losses'))\n",
    "sys.path.append(os.path.abspath('/projectnb/textconv/dgwave/AudioSCC/models'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0bec28fd-ab6d-4215-a35a-2d681195f99f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from dataloader import WaveformDatasetPreload\n",
    "from sampler import RandomConsecutiveSampler\n",
    "from losses import ConsecutiveDifferenceHigherOrderLossBatch, ConsecutiveDifferenceHigherOrderLoss\n",
    "from SwissArmyModel import SeqModel, SwissArmyLayer, SeqEncoder\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm \n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ec9ceef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU: Tesla V100-SXM2-16GB\n"
     ]
    }
   ],
   "source": [
    "# Check if a GPU is available\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")  # Use the first available GPU\n",
    "    print(f\"Using GPU: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"No GPU found, using CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf4906af",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PairwiseDifferenceLoss(nn.Module):\n",
    "    def __init__(self, consecutive_size, device, scale_up=1000):\n",
    "        super(PairwiseDifferenceLoss, self).__init__()\n",
    "        self.consecutive_size = consecutive_size\n",
    "        self.device = device\n",
    "        self.scale_up  = scale_up\n",
    "\n",
    "    def forward(self, data, labels):\n",
    "        \n",
    "        ####YOU HAVE TO MAKE THIS batch by consec!!\n",
    "        data = data.view(-1, self.consecutive_size)\n",
    "        labels = labels.view(-1, self.consecutive_size)\n",
    "        batch_size = data.shape[0]\n",
    "        #print(data.shape, labels.shape)\n",
    "        # Expand the tensor to compute pairwise differences\n",
    "        data_expanded1 = data.unsqueeze(2).expand(batch_size, self.consecutive_size, self.consecutive_size)\n",
    "        data_expanded2 = data.unsqueeze(1).expand(batch_size, self.consecutive_size, self.consecutive_size)\n",
    "        \n",
    "        # Compute differences between data and labels\n",
    "        data_differences = (data_expanded1 - data_expanded2)\n",
    "        #print(data_expanded1 == data_expanded2)\n",
    "        #print(data_expanded1,data_expanded2, data_differences)\n",
    "        # Compute differences with the labels\n",
    "        labels_expanded1 = labels.unsqueeze(2).expand(batch_size, self.consecutive_size, self.consecutive_size)\n",
    "        labels_expanded2 = labels.unsqueeze(1).expand(batch_size, self.consecutive_size, self.consecutive_size)\n",
    "        label_differences = (labels_expanded1 - labels_expanded2)\n",
    "        #print(labels_expanded1,labels_expanded1, label_differences)\n",
    "        \n",
    "        #mask = torch.triu(torch.ones(batch_size, self.consecutive_size, self.consecutive_size), diagonal=1).to(self.device)\n",
    "        \n",
    "        differences = (( data_differences*self.scale_up - label_differences*self.scale_up)**2)\n",
    "        #print(differences.shape)\n",
    "        # Apply a mask to ignore upper triangle\n",
    "        \n",
    "       \n",
    "        #print(differences)\n",
    "        # Compute the mean to return a scalar loss\n",
    "        loss = differences.mean()\n",
    "        \n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6f7b9dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(10555.5487, dtype=torch.float64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.tensor([[1,2,3,4,5,6]]).to(float)\n",
    "t2 = torch.tensor([[1.05,2.2,3.1,4.2,5.1,6.0]]).to(float)\n",
    "pd = PairwiseDifferenceLoss(3, \"cpu\")\n",
    "pd(t,t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "efebe3c2-8ce3-46c1-ac76-05a8214a5f3a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def generate_sine_tensor(num_bits, length):\n",
    "    # Create an array of integers from 0 to length - 1\n",
    "    t = np.arange(length)\n",
    "    # Generate the sine waves for each bit\n",
    "    sine_tensor = np.zeros((length, num_bits))  # Initialize the tensor\n",
    "    \n",
    "    for i in range(num_bits):\n",
    "        frequency = (np.pi / (2 ** i))  # Calculate frequency based on the number of bits\n",
    "        sine_tensor[:, i] = np.cos(frequency * (t))  # Fill the tensor with sine values\n",
    "\n",
    "    return sine_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d117af1-8ee4-4578-9eac-936e89d0d57e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "num_bits = 30\n",
    "max_len = 50_000\n",
    "seq_bits = 10\n",
    "seq_max_len = 2\n",
    "directory = \"/projectnb/textconv/dgwave/AudioSCC/data/digits_two/\"\n",
    "terminal_pad = 11\n",
    "seq_vocab_len = 10\n",
    "\n",
    "# Sampler setup as before\n",
    "batch_size = 800\n",
    "consecutive_size = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "638eda3a-1bd4-4231-ba3d-49c7a4655907",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50000, 30])\n",
      "torch.Size([2, 10])\n"
     ]
    }
   ],
   "source": [
    "t_input = torch.tensor(generate_sine_tensor(num_bits,max_len)).float()\n",
    "print(t_input.shape)\n",
    "\n",
    "seq_t = torch.tensor(generate_sine_tensor(seq_bits,seq_max_len)).float()\n",
    "print(seq_t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56cb86a2-a43c-4365-a5f1-3684461a3b18",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,\n",
       "          1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00],\n",
       "        [-1.0000e+00,  6.1232e-17,  7.0711e-01,  9.2388e-01,  9.8079e-01,\n",
       "          9.9518e-01,  9.9880e-01,  9.9970e-01,  9.9992e-01,  9.9998e-01]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23d19853-d5b9-4caf-9e8e-a0167ba150b5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,\n",
       "          1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00],\n",
       "        [-1.0000e+00,  6.1232e-17,  7.0711e-01,  9.2388e-01,  9.8079e-01,\n",
       "          9.9518e-01,  9.9880e-01,  9.9970e-01,  9.9992e-01,  9.9998e-01]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1980676f-4a26-468c-bba3-7d14cb894683",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset = WaveformDatasetPreload(directory, t_input, max_len, terminal_pad, seq_vocab_len, seq_max_len, seq_t)\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "sampler = RandomConsecutiveSampler(dataset, batch_size, consecutive_size)\n",
    "\n",
    "# DataLoader\n",
    "dataloader = DataLoader(dataset, batch_sampler=sampler, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d0c2984f-1270-46ee-a372-ba228a569f42",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waveform data: torch.Size([16000, 1]) torch.float32\n",
      "Time step: torch.Size([16000, 30]) torch.float32\n",
      "Target tensor: torch.Size([16000, 1]) torch.float32\n",
      "File index: torch.Size([16000, 2]) torch.int64\n",
      "File index: torch.Size([16000, 2, 10]) torch.float32\n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "Waveform data: torch.Size([16000, 1]) torch.float32\n",
      "Time step: torch.Size([16000, 30]) torch.float32\n",
      "Target tensor: torch.Size([16000, 1]) torch.float32\n",
      "File index: torch.Size([16000, 2]) torch.int64\n",
      "File index: torch.Size([16000, 2, 10]) torch.float32\n",
      "tensor([[ 1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,\n",
      "          1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00],\n",
      "        [-1.0000e+00,  6.1232e-17,  7.0711e-01,  9.2388e-01,  9.8079e-01,\n",
      "          9.9518e-01,  9.9880e-01,  9.9970e-01,  9.9992e-01,  9.9998e-01]])\n",
      "Waveform data: torch.Size([16000, 1]) torch.float32\n",
      "Time step: torch.Size([16000, 30]) torch.float32\n",
      "Target tensor: torch.Size([16000, 1]) torch.float32\n",
      "File index: torch.Size([16000, 2]) torch.int64\n",
      "File index: torch.Size([16000, 2, 10]) torch.float32\n",
      "tensor([[ 1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,\n",
      "          1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00],\n",
      "        [-1.0000e+00,  6.1232e-17,  7.0711e-01,  9.2388e-01,  9.8079e-01,\n",
      "          9.9518e-01,  9.9880e-01,  9.9970e-01,  9.9992e-01,  9.9998e-01]])\n",
      "Waveform data: torch.Size([16000, 1]) torch.float32\n",
      "Time step: torch.Size([16000, 30]) torch.float32\n",
      "Target tensor: torch.Size([16000, 1]) torch.float32\n",
      "File index: torch.Size([16000, 2]) torch.int64\n",
      "File index: torch.Size([16000, 2, 10]) torch.float32\n",
      "tensor([[ 1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,\n",
      "          1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00],\n",
      "        [-1.0000e+00,  6.1232e-17,  7.0711e-01,  9.2388e-01,  9.8079e-01,\n",
      "          9.9518e-01,  9.9880e-01,  9.9970e-01,  9.9992e-01,  9.9998e-01]])\n",
      "Waveform data: torch.Size([16000, 1]) torch.float32\n",
      "Time step: torch.Size([16000, 30]) torch.float32\n",
      "Target tensor: torch.Size([16000, 1]) torch.float32\n",
      "File index: torch.Size([16000, 2]) torch.int64\n",
      "File index: torch.Size([16000, 2, 10]) torch.float32\n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "Waveform data: torch.Size([16000, 1]) torch.float32\n",
      "Time step: torch.Size([16000, 30]) torch.float32\n",
      "Target tensor: torch.Size([16000, 1]) torch.float32\n",
      "File index: torch.Size([16000, 2]) torch.int64\n",
      "File index: torch.Size([16000, 2, 10]) torch.float32\n",
      "tensor([[ 1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,\n",
      "          1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00],\n",
      "        [-1.0000e+00,  6.1232e-17,  7.0711e-01,  9.2388e-01,  9.8079e-01,\n",
      "          9.9518e-01,  9.9880e-01,  9.9970e-01,  9.9992e-01,  9.9998e-01]])\n",
      "Waveform data: torch.Size([16000, 1]) torch.float32\n",
      "Time step: torch.Size([16000, 30]) torch.float32\n",
      "Target tensor: torch.Size([16000, 1]) torch.float32\n",
      "File index: torch.Size([16000, 2]) torch.int64\n",
      "File index: torch.Size([16000, 2, 10]) torch.float32\n",
      "tensor([[ 1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,\n",
      "          1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00],\n",
      "        [-1.0000e+00,  6.1232e-17,  7.0711e-01,  9.2388e-01,  9.8079e-01,\n",
      "          9.9518e-01,  9.9880e-01,  9.9970e-01,  9.9992e-01,  9.9998e-01]])\n",
      "Waveform data: torch.Size([16000, 1]) torch.float32\n",
      "Time step: torch.Size([16000, 30]) torch.float32\n",
      "Target tensor: torch.Size([16000, 1]) torch.float32\n",
      "File index: torch.Size([16000, 2]) torch.int64\n",
      "File index: torch.Size([16000, 2, 10]) torch.float32\n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "Waveform data: torch.Size([16000, 1]) torch.float32\n",
      "Time step: torch.Size([16000, 30]) torch.float32\n",
      "Target tensor: torch.Size([16000, 1]) torch.float32\n",
      "File index: torch.Size([16000, 2]) torch.int64\n",
      "File index: torch.Size([16000, 2, 10]) torch.float32\n",
      "tensor([[ 1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,\n",
      "          1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00],\n",
      "        [-1.0000e+00,  6.1232e-17,  7.0711e-01,  9.2388e-01,  9.8079e-01,\n",
      "          9.9518e-01,  9.9880e-01,  9.9970e-01,  9.9992e-01,  9.9998e-01]])\n",
      "Waveform data: torch.Size([16000, 1]) torch.float32\n",
      "Time step: torch.Size([16000, 30]) torch.float32\n",
      "Target tensor: torch.Size([16000, 1]) torch.float32\n",
      "File index: torch.Size([16000, 2]) torch.int64\n",
      "File index: torch.Size([16000, 2, 10]) torch.float32\n",
      "tensor([[ 1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,\n",
      "          1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00],\n",
      "        [-1.0000e+00,  6.1232e-17,  7.0711e-01,  9.2388e-01,  9.8079e-01,\n",
      "          9.9518e-01,  9.9880e-01,  9.9970e-01,  9.9992e-01,  9.9998e-01]])\n",
      "Waveform data: torch.Size([16000, 1]) torch.float32\n",
      "Time step: torch.Size([16000, 30]) torch.float32\n",
      "Target tensor: torch.Size([16000, 1]) torch.float32\n",
      "File index: torch.Size([16000, 2]) torch.int64\n",
      "File index: torch.Size([16000, 2, 10]) torch.float32\n",
      "tensor([[ 1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,\n",
      "          1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00],\n",
      "        [-1.0000e+00,  6.1232e-17,  7.0711e-01,  9.2388e-01,  9.8079e-01,\n",
      "          9.9518e-01,  9.9880e-01,  9.9970e-01,  9.9992e-01,  9.9998e-01]])\n"
     ]
    }
   ],
   "source": [
    "iteration = 0\n",
    "\n",
    "for batch in dataloader:\n",
    "    wav_data, t_step, target, file_idx, seq_inputs = batch #right now this wraps arround, just fyi.  not sure its a bad thing.\n",
    "\n",
    "    print(\"Waveform data:\", wav_data.shape,wav_data.dtype)\n",
    "    print(\"Time step:\", t_step.shape,t_step.dtype)\n",
    "    print(\"Target tensor:\", target.shape,target.dtype)\n",
    "    print(\"File index:\", file_idx.shape,file_idx.dtype)\n",
    "    print(\"File index:\", seq_inputs.shape,seq_inputs.dtype)\n",
    "    print(seq_inputs[0])\n",
    "    #print(wav_data)\n",
    "    #print(prev_target)\n",
    "    iteration = iteration + 1\n",
    "    if iteration > 10:\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "47f6679b-16f1-4c3f-b363-92b2dc5e141a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "config = {\n",
    "    't_seq_bits': seq_bits,  # Example value for the input bit size\n",
    "    't_seq_len': seq_max_len,    # Example value for the sequence length\n",
    "    't_bits': num_bits,      # Example value for the bits used in the decoder\n",
    "\n",
    "    'encoder': {\n",
    "        't_layer_dim': 0,               # Example hidden layer dimension for encoder\n",
    "        't_num_layers': 0,                # Example number of layers in the encoder's initial layer\n",
    "        'fc_layers': 1,                   # Example number of fully connected layers in the encoder\n",
    "        'encoder_layers': 1,              # Example number of encoder layers\n",
    "        'one_hot_vocab_len': 10,          # Vocabulary size for one-hot encoding\n",
    "        'one_hot_embedding_dim': 256,       # Embedding dimension for one-hot encoding\n",
    "        'output_dim':128\n",
    "    },\n",
    "\n",
    "    'decoder': {\n",
    "        't_layer_dim': 0,                # Example hidden layer dimension for decoder\n",
    "        't_num_layers': 0,                # Example number of layers in the decoder's initial layer\n",
    "        'fc_layers': 1,                   # Example number of fully connected layers in the decoder\n",
    "        'decoder_layers': 1\n",
    "    },\n",
    "\n",
    "    'output': {\n",
    "        'mse_output_layers': 5,           # Number of layers in the MSE output head\n",
    "        'mse_dim': 256,                     # Hidden dimension for the MSE output head\n",
    "        'bce_output_layers': 1,            # Number of layers in the BCE output head\n",
    "        'bce_dim': 10                     # Hidden dimension for the BCE output head\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e6fbf898",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SeqModel(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2c22d1e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SeqModel(\n",
       "  (encoder): SeqEncoder(\n",
       "    (initial_layer): SwissArmyLayer(\n",
       "      (t_layers): ModuleList()\n",
       "      (embedding): Embedding(11, 256, padding_idx=10)\n",
       "      (layers): ModuleList(\n",
       "        (0): Linear(in_features=266, out_features=266, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (encoder_layers): ModuleList(\n",
       "      (0): SwissArmyLayer(\n",
       "        (t_layers): ModuleList()\n",
       "        (embedding): Embedding(11, 256, padding_idx=10)\n",
       "        (layers): ModuleList(\n",
       "          (0): Linear(in_features=532, out_features=532, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): SeqDecoder(\n",
       "    (decoder_layers): ModuleList(\n",
       "      (0): SwissArmyLayer(\n",
       "        (t_layers): ModuleList()\n",
       "        (layers): ModuleList(\n",
       "          (0): Linear(in_features=562, out_features=562, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (mse_head): Sequential(\n",
       "    (0): Linear(in_features=562, out_features=256, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (7): ReLU()\n",
       "    (8): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (9): ReLU()\n",
       "    (10): Linear(in_features=256, out_features=1, bias=True)\n",
       "  )\n",
       "  (bce_head): Sequential(\n",
       "    (0): Linear(in_features=562, out_features=10, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=10, out_features=1, bias=True)\n",
       "    (3): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "68acd0b6-4bed-4fc9-bd9e-adc904bd42f1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:   7%|▋         | 92/1405 [00:30<07:12,  3.03it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m#for batch in dataloader:\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m tqdm(dataloader, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     16\u001b[0m     wav_data, t_step, target, file_idx, seq_inputs \u001b[38;5;241m=\u001b[39m batch\n\u001b[1;32m     17\u001b[0m     wav_data \u001b[38;5;241m=\u001b[39m wav_data\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tqdm/std.py:1195\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1192\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1194\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1195\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1196\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1197\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1198\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m/share/pkg.7/pytorch/1.13.1/install/lib/SCC/../python3.10/site-packages/torch/utils/data/dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    626\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    627\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 628\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    629\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    631\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    632\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/share/pkg.7/pytorch/1.13.1/install/lib/SCC/../python3.10/site-packages/torch/utils/data/dataloader.py:1316\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1313\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[1;32m   1315\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1316\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1317\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1318\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[1;32m   1319\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m/share/pkg.7/pytorch/1.13.1/install/lib/SCC/../python3.10/site-packages/torch/utils/data/dataloader.py:1282\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1278\u001b[0m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   1279\u001b[0m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   1280\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1281\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 1282\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1283\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m   1284\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m/share/pkg.7/pytorch/1.13.1/install/lib/SCC/../python3.10/site-packages/torch/utils/data/dataloader.py:1120\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m   1108\u001b[0m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1109\u001b[0m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1117\u001b[0m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1118\u001b[0m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1119\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1120\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1121\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[1;32m   1122\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1123\u001b[0m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1124\u001b[0m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1125\u001b[0m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "File \u001b[0;32m/share/pkg.8/python3/3.10.12/install/lib/python3.10/multiprocessing/queues.py:113\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m block:\n\u001b[1;32m    112\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m deadline \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[0;32m--> 113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    114\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll():\n",
      "File \u001b[0;32m/share/pkg.8/python3/3.10.12/install/lib/python3.10/multiprocessing/connection.py:257\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_closed()\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_readable()\n\u001b[0;32m--> 257\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/share/pkg.8/python3/3.10.12/install/lib/python3.10/multiprocessing/connection.py:424\u001b[0m, in \u001b[0;36mConnection._poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_poll\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout):\n\u001b[0;32m--> 424\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    425\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(r)\n",
      "File \u001b[0;32m/share/pkg.8/python3/3.10.12/install/lib/python3.10/multiprocessing/connection.py:931\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    928\u001b[0m     deadline \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic() \u001b[38;5;241m+\u001b[39m timeout\n\u001b[1;32m    930\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 931\u001b[0m     ready \u001b[38;5;241m=\u001b[39m \u001b[43mselector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    932\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ready:\n\u001b[1;32m    933\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [key\u001b[38;5;241m.\u001b[39mfileobj \u001b[38;5;28;01mfor\u001b[39;00m (key, events) \u001b[38;5;129;01min\u001b[39;00m ready]\n",
      "File \u001b[0;32m/share/pkg.8/python3/3.10.12/install/lib/python3.10/selectors.py:416\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 416\u001b[0m     fd_event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "prev_target_list = []\n",
    "mse_loss_fn = nn.MSELoss()\n",
    "bce_loss_fn = nn.BCELoss()\n",
    "cdifb_loss = ConsecutiveDifferenceHigherOrderLossBatch(consecutive_size,order=3)\n",
    "cdif_loss = ConsecutiveDifferenceHigherOrderLoss(consecutive_size,order=3)\n",
    "pd = PairwiseDifferenceLoss(consecutive_size, device, scale_up = 100_000)\n",
    "num_epochs = 1\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    \n",
    "    #for batch in dataloader:\n",
    "    for batch in tqdm(dataloader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "        wav_data, t_step, target, file_idx, seq_inputs = batch\n",
    "        wav_data = wav_data.to(device)\n",
    "        t_step = t_step.to(device)\n",
    "        target = target.to(device)\n",
    "        file_idx = file_idx.to(device)\n",
    "        seq_inputs = seq_inputs.to(device)\n",
    "        #print(wav_data.dtype, t_step.dtype, target.dtype, file_idx.dtype, seq_inputs.dtype)\n",
    "        \n",
    "        bce_output, mse_output = model(seq_inputs,file_idx,t_step)\n",
    "        # Compute losses\n",
    "        #bce_output = bce_output.to(torch.float64)\n",
    "        #print(bce_output.dtype, target.dtype)\n",
    "        mse_loss = mse_loss_fn(mse_output*target, wav_data)  # Assuming the target is for MSE # is this accomplishing what i want?\n",
    "\n",
    "        bce_loss = bce_loss_fn(bce_output, target)  # Assuming the target is for BCE\n",
    "        cdif = cdif_loss(mse_output*target, wav_data)\n",
    "        #bc = bc_loss(outputs, targets)\n",
    "        cdif_b = cdifb_loss(mse_output*target, wav_data)\n",
    "        \n",
    "        #total_loss = pd(mse_output*target, wav_data)\n",
    "        # Combine losses (you can weight them if needed)\n",
    "        total_loss = 0.1*mse_loss + 0.1*bce_loss + 0.8*cdif  + 0.3*cdif_b #mess with mse\n",
    "        #print(total_loss.dtype)\n",
    "        #print(mse_loss.dtype,bce_loss.dtype,cdif.dtype, cdif_b.dtype ) #torch.float64 torch.float32 torch.float32 torch.float32\n",
    "        # Backpropagation and optimization\n",
    "        optimizer.zero_grad()\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    # Print progress for each epoch\n",
    "    #print(f\"Epoch {epoch+1}/{num_epochs} MSE: {mse_loss.item():.6f} BCE: {bce_loss.item():.6f} CDIF: {cdif.item():.6f} CDIFB: {cdif_b.item():.6f}  Total Loss: {total_loss.item():.8f}\")\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} pd: {total_loss.item():.8f}\")\n",
    "    torch.save(model, \"better_embedder_8.pth\")\n",
    "print(\"all done sweetheart <3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbdc714d-bcb3-4d4b-99f6-958f27675680",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "##i need inference and then a noise term for the training prev_pred input.  \n",
    "#model = torch.load(\"better_embedder_2.pth\") ## got 0.01193226\n",
    "#model = torch.load(\"better_embedder_3.pth\") ## 8 layer encoder.  nothing amazing.\n",
    "#model = torch.load(\"better_embedder_4.pth\") ## 2 layer encoder, 1 layer decoder, small af.\n",
    "#model = torch.load(\"better_embedder_5.pth\") #this is interesting.  it has some weird stuff, but i think seq bits might be busted.\n",
    "#model = torch.load(\"better_embedder_6.pth\")\n",
    "#model = torch.load(\"better_embedder_7.pth\") ##this is with the new loss but i upped the lr\n",
    "model = torch.load(\"better_embedder_8.pth\")\n",
    "#model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb58971-6449-4300-b20e-b1d18d665beb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.io import wavfile\n",
    "file_path = '/projectnb/textconv/dgwave/AudioSCC/data/data_files/011.wav'\n",
    "sample_rate, data_test = wavfile.read(file_path)\n",
    "sample_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856a4bd1-7e49-4755-b56d-a4669803fc04",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "digits = \"00\"\n",
    "\n",
    "model.eval()\n",
    "rep = t_input.shape[0] #this is good, \n",
    "input_seq_1 = seq_t #[:-1]\n",
    "\n",
    "file = [int(char) for char in digits] \n",
    "input_seq_1[len(file):] = 0\n",
    "\n",
    "file = file + [10] * (seq_max_len - len(file))\n",
    "file = torch.tensor(file)\n",
    "print(file, file.shape)\n",
    "file = file.unsqueeze(0).repeat(rep,1)\n",
    "input_seq_eval = input_seq_1.unsqueeze(0).repeat(rep, 1,1)\n",
    "\n",
    "print(file.shape,input_seq_eval.shape, t_input.shape )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9cc06ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2e594b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming input shapes: (batch_size, ...)\n",
    "# Define your eval batch size\n",
    "eval_batch_size = 200\n",
    "\n",
    "# Initialize lists to store outputs\n",
    "bce_outputs = []\n",
    "mse_outputs = []\n",
    "\n",
    "# Get the total number of batches\n",
    "total_batches = (file.shape[0] + eval_batch_size - 1) // eval_batch_size\n",
    "\n",
    "# Loop over batches\n",
    "for i in range(total_batches):\n",
    "    # Define the start and end of the batch\n",
    "    start_idx = i * eval_batch_size\n",
    "    end_idx = min((i + 1) * eval_batch_size, file.shape[0])\n",
    "\n",
    "    # Slice the batch from each input\n",
    "    batch_file = file[start_idx:end_idx]\n",
    "    batch_file = batch_file.to(device)\n",
    "    batch_input_seq_eval = input_seq_eval[start_idx:end_idx]\n",
    "    batch_input_seq_eval = batch_input_seq_eval.to(device)\n",
    "    batch_t_input = t_input[start_idx:end_idx]\n",
    "    batch_t_input = batch_t_input.to(device)\n",
    "\n",
    "    # Run the model in evaluation mode (assuming the model is in eval mode already)\n",
    "    with torch.no_grad():  # Disable gradient calculation for evaluation\n",
    "        bce_output, mse_output = model(batch_input_seq_eval, batch_file, batch_t_input)\n",
    "    \n",
    "    # Append the outputs\n",
    "    bce_outputs.append(bce_output)\n",
    "    mse_outputs.append(mse_output)\n",
    "\n",
    "# Optionally, concatenate the outputs into single tensors\n",
    "bce_outputs = torch.cat(bce_outputs, dim=0)\n",
    "mse_outputs = torch.cat(mse_outputs, dim=0)\n",
    "\n",
    "# Now bce_outputs and mse_outputs contain the model outputs for all batches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5115ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "# Create a figure and plot both outputs\n",
    "plt.figure(figsize=(20, 6))\n",
    "\n",
    "# Plot BCE outputs\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(bce_outputs.cpu().numpy(), label='BCE Output')\n",
    "plt.title('BCE Output')\n",
    "plt.xlabel('Batch index')\n",
    "plt.ylabel('BCE Value')\n",
    "plt.legend()\n",
    "\n",
    "# Plot MSE outputs\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(mse_outputs.cpu().numpy(), label='MSE Output', color='orange')\n",
    "plt.title('MSE Output')\n",
    "plt.xlabel('Batch index')\n",
    "plt.ylabel('MSE Value')\n",
    "plt.legend()\n",
    "\n",
    "# Display the plots\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10e259a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from scipy.io.wavfile import write\n",
    "\n",
    "\n",
    "def tensor_to_wav(tensor, filename, sample_rate=44100,cut_off=-1 ):\n",
    "    # Convert tensor to numpy array and detach if needed\n",
    "    data = tensor.detach().cpu().numpy()[:cut_off]\n",
    "    # Normalize to the range [-1, 1]\n",
    "    #data = data / np.max(np.abs(data))\n",
    "\n",
    "    # Convert to 16-bit PCM format (values between -32768 and 32767)\n",
    "    data_int16 = np.int16(data * 32768)\n",
    "\n",
    "    # Write the .wav file\n",
    "    write(filename, sample_rate, data_int16)\n",
    "    print(f\"Saved as {filename}\")\n",
    "\n",
    "# Example usage with your model predictions (assuming predictions are in range -1 to 1):\n",
    "# predictions is the output tensor from the model\n",
    "tensor_to_wav(mse_outputs, \"test_mult_first_bad.wav\",sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa5bbd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "\n",
    "# Play the .wav file\n",
    "Audio(\"test_mult_first_bad.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48d16eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078eb344",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
